# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cKmUTauiQ1K62hSZ4RIKsMCI9Zmw-JVJ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('https://github.com/YBIFoundation/Dataset/raw/main/Bank%20Churn%20Modelling.csv')

df.head()

df.info()

df.describe()

df.duplicated().sum()

df = df.set_index('CustomerId')

df.info()

"""For ML we cant proceed with string, object or text so we have to replace those with boolean datatype"""

df['Geography'].value_counts()

df.replace({'Geography':{'France': 2,'Germany':1, 'Spain' : 0 }},inplace = True)

df['Gender'].value_counts()

df.replace({'Gender':{'Female':1,'Male':0}},inplace = True)

df['Num Of Products'].value_counts()

df.replace({'Num Of Products':{1:0,2:1,3:1,4:1}},inplace = True)

df['Has Credit Card'].value_counts()

df['Is Active Member'].value_counts()

df.loc[(df['Balance'] == 0), 'Churn'].value_counts()

"""created at column named zero Balance"""

df['Zero Balance'] = np.where(df['Balance'] == 0, 1, 0)

df['Zero Balance'].hist()

df.groupby(['Churn', 'Geography']).count()

df.columns

X = df.drop(['Churn','Surname'], axis = 1)

y = df['Churn']

X.shape, y.shape

df['Churn'].value_counts()

sns.countplot(x = 'Churn', data = df)

#for undersampling or oversampling issue we will import library called RandomUnderSampler

from imblearn.under_sampling import RandomUnderSampler

rus =  RandomUnderSampler(random_state = 2529)

X_rus, y_rus = rus.fit_resample(X,y)

X_rus.shape, y_rus.shape, X.shape, y.shape

y_rus.value_counts()

y.value_counts()

y_rus.plot(kind = 'hist')

X_rus.value_counts()

X.value_counts()

y.plot(kind = 'hist')

from imblearn.over_sampling import RandomOverSampler

ros = RandomOverSampler(random_state = 2529)

X_ros, y_ros = ros.fit_resample(X,y)

X_ros.shape, y_ros.shape, X.shape, y.shape

y_ros.value_counts()

y.value_counts()

y_ros.plot(kind = 'hist')

from sklearn.model_selection import train_test_split

"""Split original data

"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2529)

# Split RandomUnderSampling Data

X_train_rus, X_test_rus, y_train_rus, y_test_rus = train_test_split(X_rus, y_rus, test_size = 0.3, random_state = 2529)

"""# Split RandomOverSampling Data"""

X_train_ros, X_test_ros, y_train_ros, y_test_ros = train_test_split(X_ros, y_ros, test_size = 0.3, random_state = 2529)

"""Standardize Features"""

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()

"""standardize original data"""

X_train[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']] = sc.fit_transform(X_train[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']])

X_test[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']] = sc.fit_transform(X_test[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']])

# standardize undersampling data

X_rus_train[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']] = sc.fit_transform(X_rus_train[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']])

X_rus_test[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']] = sc.fit_transform(X_rus_test[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']])

# Standardize oversampling data

X_ros_train[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']] = sc.fit_transform(X_ros_train[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']])

X_ros_test[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']] = sc.fit_transform(X_ros_test[['CreditScore', 'Age', 'Tenure', 'Balance', 'Estimated Salary']])

from sklearn.svm import SVC

"""For og Dataset"""

svc = SVC()

svc.fit(X_train, y_train)

y_pred = svc.predict(X_test)

"""For RUS dataset"""

svc.fit(X_rus_train,y_rus_train)

y_pred = svc.predict(X_rus_test)

"""For ROS dataset"""

svc.fit(X_ros_train, y_ros_train )

y_pred = svc.predict(X_ros_test)

y_test.value_counts()



"""svc.fir"""

y_ros_pred = svc.predict(X_ros_test)

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, classification_report

confusion_matrix(y_ros_test, y_ros_pred)

classification_report(y_ros_test, y_ros_pred)

"""ROS mode

"""

confusion_matrix(y_ros_test, y_ros_pred)

classification_report(y_ros_test, y_ros_pred)

from sklearn.model_selection import GridSearchCV

ParameterGrid = {'C' : [0.1,1,10],
                 'gamma' : [1,0.1,0.01],
                 'kernel' : ['rbf'],
                 'class_weight' : ['balanced']}

grid = GridSearchCV(SVC(), ParameterGrid, refit = True, verbose = 2, cv = 2)
grid.fit(X_train, y_train)

print = (grid.best_estimator_)

grid_pred = grid.predict(X_test)

confusion_matrix(y_test, grid_pred)

print= __builtins__.print(classification_report(y_test, grid_pred))

ParameterGrid = {'C' : [0.1,1,10],
                 'gamma' : [1,0.1,0.01],
                 'kernel' : ['rbf'],
                 'class_weight' : ['balanced']}

grid = GridSearchCV(SVC(), ParameterGrid, refit = True, verbose = 2, cv = 2)
grid.fit(X_ros_train, y_ros_train)

print = (grid.best_estimator_)

grid_pred = grid.predict(X_ros_test)

confusion_matrix(y_ros_test, grid_pred)

classification_report(y_ros_test, grid_pred)